# Cortical-Sensory-Mapping-fMRI
Pipeline for mapping cortical sensory integration from fMRI using the HCP-MMP atlas, with downsampling to fsaverage5, non-negative regression, and HSV visualization.



**A. 00_split.py**

The script implements sensory-integration mapping on **fsaverage5** space (10,242 vertices per hemisphere; 20,484 total). "Seeds" are V1, S1 (areas 3a/3b/1/2), and A1 from HCP-MMP1 annotations. For each subject, it:

(1) builds seed masks from `.annot`, 

(2) extracts seed mean time series from LH/RH functional GIFTIs resampled to fsaverage5,

(3) performs non-negative regression (beta â‰¥ 0) per vertex using the three seed series as predictors, 

(4) converts betas to HSV/RGB color encodings, 

(5) aggregates to group level with circular stats for hue.

Imports 

```python
numpy
scipy
nibabel
sklearn.linear_model.LinearRegression(positive=True)
matplotlib.colors # for HSV <-> RGB mapping
tqdm # progress bars
pingouin # circular means (group-level hue aggregation)

```

**B. 01_sensory_mapping_preprocess.py**

`01_sensory_mapping_preprocess.py` runs the actual mapping on fsaverage5 and constructs primary ROI masks (V1, S1, A1) from HCP MMP1 annotations, loads LH/RH time series, performs non-negative regression (V1/S1/A1 seeds each vertex), converts to HSV/angle representation, and aggregates to group level outputs. The pipeline expects LH and RH surfaces to be fsaverage5 (10,242 vertices per hemisphere) and concatenated as [LH, RH] 20,484 vertices total. 

As a recapitulation, 

1. Construct primry masks from HCP-MMP1 fs5 annotations:
   * V1, S1 (3a/3b/1/2), A1 labels are looked up by name in lh/rh .annot tables.
   * Boolean masks are built per hemisphere and concatenated (LH || RH).

2. Load cohort CSV
   * Requires columns: `subject_id`, `lh_path`, `rh_path`.
   * Optional --n-max allows smoke testing on a few subjects.

3. For each subjec:
   * Load LH/RH time series -> [10242 x T] per hemi; concatenate to [20484 x T].
   * Compute seed means for V1/S1/A1 using masks.
   * Fit non-negative linear regression (sklearn positive = True) from seed time series (X) to each vertex time series (Y).
   * Derive per-vertex R^2 and stack into RGBA: [4 x 20484].
   * Save per-subject RGBA as .npy inside out_root/subjects/.

4. Group aggregation:
   * Stack subjects -> [S x 4 x 20484].
   * Convert each subject's RGB betas to hue/angle; rank-normalize R^2 to get saturation.
   * Compute circular mean of angles across subjects and aggregate rank R^2.
   * Save group-level arrays (theta, r2rank, rgb).


To run, verify deps are installed


```bash
python3 -m pip install --upgrade pip
python3 -m pip install numpy scipy scikit-learn nibabel pingouin tqdm matplotlib 
```

Verify required inputs exist

```bash
ls -l data/autism_split.csv data/control_split.csv
ls -l data/HCP-MMP1.fsaverage/lh.HCP-MMP1.fsaverage5.annot
ls -l data/HCP-MMP1.fsaverage/rh.HCP-MMP1.fsaverage5.annot
```


Run treatment cohort:

```bash
python3 01_sensory_mapping_preprocess.py \
  --csv ./data/control_split.csv \
  --group control \
  --lh-annot ./data/HCP-MMP1.fsaverage/lh.HCP-MMP1.fsaverage5.annot \
  --rh-annot ./data/HCP-MMP1.fsaverage/rh.HCP-MMP1.fsaverage5.annot \
  --out ./out_fs5_control
```
**C. 02_statistic_anglecomp_perm.py**


